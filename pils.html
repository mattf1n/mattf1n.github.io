<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Stealing Secret Prompts With 3\times Accuracy</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    html { -webkit-text-size-adjust: 100%; }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
      margin-bottom: 0em;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
  <link rel="stylesheet" href="style/blog.css" />
  <script
    type="module"
    src="https://gradio.s3-us-west-2.amazonaws.com/5.34.2/gradio.js"
  ></script>
  <script
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
</head>
<body>
<header id="title-block-header">
<h1 class="title">Stealing Secret Prompts With 3<span
class="math inline">\(\times\)</span> Accuracy</h1>
</header>
<ul>
<li><a href="https://arxiv.org/abs/2506.17090">Paper</a></li>
<li><a href="https://github.com/dill-lab/PILS">Code</a></li>
<li><a
href="https://huggingface.co/dill-lab/pils-32-llama2-chat-7b">Model</a></li>
</ul>
<table>
<thead>
<tr>
<th style="text-align: left;">Date</th>
<th style="text-align: left;">Authors</th>
<th style="text-align: left;">Affiliations</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">June 2025</td>
<td style="text-align: left;"><a
href="https://themurtazanazir.github.io">Murtaza Nazir</a></td>
<td style="text-align: left;">Independent researcher</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;"><a
href="https://mattf1n.github.io">Matthew Finlayson</a></td>
<td style="text-align: left;"><a
href="https://dill-lab.github.io/">DILL</a> &amp; <a
href="https://inklab.usc.edu/">INK Labs</a>, University of Southern
California</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;"><a href="https://jxmo.io">Jack
Morris</a></td>
<td style="text-align: left;">Cornell University</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;"><a href="https://www.seanre.com/">Xiang
Ren</a></td>
<td style="text-align: left;"><a href="https://inklab.usc.edu/">INK
Lab</a>, University of Southern California</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;"><a href="https://swabhs.com">Swabha
Swayamdipta</a></td>
<td style="text-align: left;"><a href="https://dill-lab.github.io/">DILL
Lab</a>, University of Southern California</td>
</tr>
</tbody>
</table>
<p><gradio-app src="https://425f87d1aea98fc174.gradio.live"></gradio-app></p>
<p class="tldr">
<abbr>TL;DR</abbr>: We trained a <em>language model inverter</em> to
guess secret hidden prompts from language model outputs, and it
absolutely crushes the competition. How? By representing language model
outputs <em>the right way</em>.
</p>
<p class="firstpar">
When interacting with an <abbr>AI</abbr> model via an <abbr>API</abbr>,
you never know <em>exactly</em> what prompt is being sent to the model.
Providers routinely modify user prompts—prepending secret system
messages, or <a
href="https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/prompt-transformation">making
other changes</a>—sometimes for security reasons, or to <a
href="https://promptbase.com/">protect trade secrets</a>. A <a
href="https://github.com/0xeb/TheBigPromptLibrary">whole cottage
industry</a> has emerged around reverse engineering these “secret”
system messages from language model outputs.
</p>
<p>While early methods for stealing prompts were themselves prompt-based
(e.g., asking the model to repeat the hidden prompt), neural methods for
prompt recovery are now emerging. This approach—known as <em>language
model inversion</em> <span class="citation"
data-cites="morris2024language">[<a href="#ref-morris2024language"
role="doc-biblioref">1</a>]</span>—trains a model (known as an
<em>inverter</em>) to guess hidden prompts by looking at the outputs
from a target model. Compared to prompting attacks, inversion attacks
can be harder to detect and defend against, since they can work even if
the model doesn’t repeat the prompt.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Secret prompt</th>
<th style="text-align: left;">Output (Llama 2 Chat)</th>
<th style="text-align: left;">Inverter guess</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Tell me about a time you felt afraid</td>
<td style="text-align: left;">I’m just an AI, I don’t have personal
experiences or emotions, including fear.</td>
<td style="text-align: left;">Tell me about a time you felt afraid</td>
</tr>
</tbody>
</table>
<p>So far, language model inversion’s success has been limited: exact
prompt recovery rates rarely exceed 25%. Looking at the existing
methods, we observed that none fully exploit the rich information hidden
in the model outputs. Prior approaches supply the inverter with either
the <em>text</em> output <span class="citation"
data-cites="zhang-etal-2024-extracting">[<a
href="#ref-zhang-etal-2024-extracting"
role="doc-biblioref">2</a>]</span> or the <em>next token logprobs</em>
from just one generation step<a href="#fn1" class="footnote-ref"
id="fnref1" role="doc-noteref"><sup>1</sup></a> <span class="citation"
data-cites="morris2024language">[<a href="#ref-morris2024language"
role="doc-biblioref">1</a>]</span>.</p>
<p>The chief bottleneck in prior work is the <em>size</em> of the target
model output/inverter input. Next-token logprobs are information-rich,
but enormous: each generation step yields a vector as large as the
entire model vocabulary, which ranges from 35,000 to over 200,000
tokens. Meanwhile, clues about the hidden prompt may only surface after
<em>many</em> generation steps, giving an advantage to text-based
inverters. Naïvely, combining these approaches by using full logprob
outputs over multiple generation steps would result in an impractically
large inverter input size of <span
class="math inline">\(|\text{vocab}|\times|\text{sequence}|.\)</span></p>
<p>We overcome this by taking advantage of a mathematical property of
modern transformers: their outputs are subject to low-dimensional linear
constraints <span class="citation" data-cites="finlayson2024logits">[<a
href="#ref-finlayson2024logits" role="doc-biblioref">3</a>]</span>.
Specifically, for a small value of <span
class="math inline">\(d\ll|\text{vocab}|\)</span>, there is a set of
<span class="math inline">\(d\)</span> tokens whose logprobs linearly
encode all the information about all the other token logprobs.<a
href="#fn2" class="footnote-ref" id="fnref2"
role="doc-noteref"><sup>2</sup></a> Therefore, we only collect logprobs
for these tokens, discarding the rest without loss of information. Thus
we bring our inverter input down to a reasonable size of <span
class="math inline">\(d\times|\text{sequence}|\)</span>.</p>
<figure>
<img src="img/fig1_transparent.png"
alt="Our inverter architecture takes advantage of the fact that there is a linear map between the logprob outputs of the model and the model’s hidden state" />
<figcaption aria-hidden="true">Our inverter architecture takes advantage
of the fact that there is a linear map between the logprob outputs of
the model and the model’s hidden state</figcaption>
</figure>
<p>The result is a <em>remarkable</em> improvement over previous
language model inversion methods. In the table below, we highlight one
of our favorite results, where we compare our inverter—called <em>prompt
inversion from logprob sequences</em>, or <abbr>PILS</abbr>—to earlier
prompt recovery approaches, as measured by <abbr>BLEU</abbr>, exact
match, and token <abbr>F1</abbr> between the actual and recovered
prompts. This particular evaluation uses the held-out <a
href="https://github.com/sahil280114/codealpaca">Alpaca Code</a>
dataset.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Inverter</th>
<th style="text-align: right;">BLEU</th>
<th style="text-align: right;">Exact match</th>
<th style="text-align: right;">Token F1</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Prompt <span class="citation"
data-cites="zhang2024effective">[<a href="#ref-zhang2024effective"
role="doc-biblioref">4</a>]</span></td>
<td style="text-align: right;">14.2</td>
<td style="text-align: right;">0.0</td>
<td style="text-align: right;">36.8</td>
</tr>
<tr>
<td style="text-align: left;">Logit2Text <span class="citation"
data-cites="morris2024language">[<a href="#ref-morris2024language"
role="doc-biblioref">1</a>]</span></td>
<td style="text-align: right;">34.6</td>
<td style="text-align: right;">2.5</td>
<td style="text-align: right;">65.2</td>
</tr>
<tr>
<td style="text-align: left;">Logit2Text++</td>
<td style="text-align: right;">44.4</td>
<td style="text-align: right;">8.2</td>
<td style="text-align: right;">73.9</td>
</tr>
<tr>
<td style="text-align: left;">Output2Prompt <span class="citation"
data-cites="zhang-etal-2024-extracting">[<a
href="#ref-zhang-etal-2024-extracting"
role="doc-biblioref">2</a>]</span></td>
<td style="text-align: right;">61.2</td>
<td style="text-align: right;">16.9</td>
<td style="text-align: right;">80.3</td>
</tr>
<tr>
<td style="text-align: left;">PILS (ours)</td>
<td style="text-align: right;"><strong>85.0</strong></td>
<td style="text-align: right;"><strong>60.5</strong></td>
<td style="text-align: right;"><strong>93.1</strong></td>
</tr>
</tbody>
</table>
<p>We invite you to browse the results from our paper, which show that
our method yields <em>large</em>, <em>consistent</em>, gains across all
datasets and metrics.</p>
<p>Curiously, we find that our model <em>generalizes</em> in an
unexpected way: when we increase the sequence length of the target model
outputs at test time, our inverter’s performance continues to improve,
<em>even after the length surpasses what the inverter saw during
training</em>.</p>
<figure>
<img src="img/fig2_transparent.png"
alt="As the target model output length increases, our inverter’s accuracy improves, even when the length surpasses the sequence lengths seen during training. See the paper for a full explanation." />
<figcaption aria-hidden="true">As the target model output length
increases, our inverter’s accuracy improves, even when the length
surpasses the sequence lengths seen during training. See the paper for a
full explanation.</figcaption>
</figure>
<p>We we believe that research on prompt recover attacks is vital for
the community. Prompts should not be considered secrets <span
class="citation" data-cites="zhang2024effective">[<a
href="#ref-zhang2024effective" role="doc-biblioref">4</a>]</span>, and
forensic tools for inspecting hidden prompts helps keep API providers
accountable. Imagine if an API provider secretly instructed their model
to introduce subtle bugs or backdoors in users’ code! This line of work
is crucial for promoting transparency, safety, and good practices in the
community.</p>
<h2 id="cite-our-work">Cite our work</h2>
<div class="sourceCode" id="cb1"><pre
class="sourceCode bibtex"><code class="sourceCode bibtex"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="va">@misc</span>{<span class="ot">nazir2025betterlanguagemodelinversion</span>,</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>      <span class="dt">title</span>={Better Language Model Inversion by Compactly Representing Next-Token Distributions}, </span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>      <span class="dt">author</span>={Murtaza Nazir and Matthew Finlayson and John X. Morris and Xiang Ren and Swabha Swayamdipta},</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>      <span class="dt">year</span>={2025},</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>      <span class="dt">eprint</span>={2506.17090},</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>      <span class="dt">archivePrefix</span>={arXiv},</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>      <span class="dt">primaryClass</span>={cs.CL},</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>      <span class="dt">url</span>={https://arxiv.org/abs/2506.17090}, </span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<h2 class="unnumbered" id="references">References</h2>
<div id="refs" class="references csl-bib-body" data-entry-spacing="0"
role="list">
<div id="ref-morris2024language" class="csl-entry" role="listitem">
<div class="csl-left-margin">1. </div><div
class="csl-right-inline">Morris JX, Zhao W, Chiu JT, et al. (2024) <a
href="https://openreview.net/forum?id=t9dWHpGkPj">Language model
inversion</a>, <em>The twelfth international conference on learning
representations</em>.</div>
</div>
<div id="ref-zhang-etal-2024-extracting" class="csl-entry"
role="listitem">
<div class="csl-left-margin">2. </div><div
class="csl-right-inline">Zhang C, Morris JX, Shmatikov V (2024) <a
href="https://doi.org/10.18653/v1/2024.emnlp-main.819">Extracting
prompts by inverting <span>LLM</span> outputs</a>, In: Al-Onaizan Y,
Bansal M, Chen Y-N (Eds.), <em>Proceedings of the 2024 conference on
empirical methods in natural language processing</em>, Miami, Florida,
USA, Association for Computational Linguistics, 14753–14777.</div>
</div>
<div id="ref-finlayson2024logits" class="csl-entry" role="listitem">
<div class="csl-left-margin">3. </div><div
class="csl-right-inline">Finlayson M, Ren X, Swayamdipta S (2024) <a
href="https://openreview.net/forum?id=oRcYFm8vyB">Logits of
<span>API</span>-protected <span>LLM</span>s leak proprietary
information</a>, <em>First conference on language modeling</em>.</div>
</div>
<div id="ref-zhang2024effective" class="csl-entry" role="listitem">
<div class="csl-left-margin">4. </div><div
class="csl-right-inline">Zhang Y, Carlini N, Ippolito D (2024) <a
href="https://openreview.net/forum?id=0o95CVdNuz">Effective prompt
extraction from language models</a>, <em>First conference on language
modeling</em>.</div>
</div>
</div>
<section id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>Language models generate text one token (<span
class="math inline">\(\approx\)</span>word) at a time. Every model has a
vocabulary of tokens, and for each step in the generation process, they
report the (log)probability of each token being the next token in the
generation.<a href="#fnref1" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>In practical settings, almost any collection of <span
class="math inline">\(d\)</span> tokens will satisfy this property.<a
href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
</body>
</html>
